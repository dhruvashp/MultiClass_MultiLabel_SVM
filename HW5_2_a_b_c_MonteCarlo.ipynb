{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HW5\n",
    "2a,b,c\n",
    "Monte Carlo (Repetition of 2a,b,c 50 times, all estimates averaged)\n",
    "\n",
    "We assume Monte Carlo means, to simply repeat the procedure 50 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "The hamming loss vector for all iterations, in %, is : \n",
      "    Hamming Loss\n",
      "1       22.2423\n",
      "2       22.2423\n",
      "3       22.2423\n",
      "4       22.2469\n",
      "5       22.2423\n",
      "6       22.2423\n",
      "7       22.2423\n",
      "8       22.2423\n",
      "9       22.2423\n",
      "10      22.2423\n",
      "11      22.2423\n",
      "12      22.2423\n",
      "13      22.1635\n",
      "14      22.2423\n",
      "15      22.1635\n",
      "16      22.2423\n",
      "17      24.5124\n",
      "18      22.1635\n",
      "19      22.2423\n",
      "20      22.2423\n",
      "21      22.2423\n",
      "22      24.5263\n",
      "23      22.2423\n",
      "24      22.2423\n",
      "25      22.2006\n",
      "26      22.1774\n",
      "27      22.2423\n",
      "28      22.2423\n",
      "29      22.2423\n",
      "30      22.2423\n",
      "31      22.2423\n",
      "32      24.5263\n",
      "33      22.2423\n",
      "34      22.2423\n",
      "35      22.2284\n",
      "36      22.2469\n",
      "37      22.1635\n",
      "38      22.2423\n",
      "39      22.2423\n",
      "40      22.2423\n",
      "41      22.2423\n",
      "42      22.2423\n",
      "43      22.1774\n",
      "44      22.2423\n",
      "45      24.5124\n",
      "46      22.2423\n",
      "47      22.2423\n",
      "48      22.2423\n",
      "49      22.2423\n",
      "50      22.2423\n",
      "The hamming distance vector for all iterations is : \n",
      "    Hamming Distance\n",
      "1          0.667269\n",
      "2          0.667269\n",
      "3          0.667269\n",
      "4          0.667408\n",
      "5          0.667269\n",
      "6          0.667269\n",
      "7          0.667269\n",
      "8          0.667269\n",
      "9          0.667269\n",
      "10         0.667269\n",
      "11         0.667269\n",
      "12         0.667269\n",
      "13         0.664906\n",
      "14         0.667269\n",
      "15         0.664906\n",
      "16         0.667269\n",
      "17         0.735372\n",
      "18         0.664906\n",
      "19         0.667269\n",
      "20         0.667269\n",
      "21         0.667269\n",
      "22         0.735789\n",
      "23         0.667269\n",
      "24         0.667269\n",
      "25         0.666018\n",
      "26         0.665323\n",
      "27         0.667269\n",
      "28         0.667269\n",
      "29         0.667269\n",
      "30         0.667269\n",
      "31         0.667269\n",
      "32         0.735789\n",
      "33         0.667269\n",
      "34         0.667269\n",
      "35         0.666852\n",
      "36         0.667408\n",
      "37         0.664906\n",
      "38         0.667269\n",
      "39         0.667269\n",
      "40         0.667269\n",
      "41         0.667269\n",
      "42         0.667269\n",
      "43         0.665323\n",
      "44         0.667269\n",
      "45         0.735372\n",
      "46         0.667269\n",
      "47         0.667269\n",
      "48         0.667269\n",
      "49         0.667269\n",
      "50         0.667269\n",
      "The hamming score/accuracy score vector for all iterations, in %, is : \n",
      "    Hamming Score\n",
      "1        80.6208\n",
      "2        80.6208\n",
      "3        80.6208\n",
      "4        80.6139\n",
      "5        80.6208\n",
      "6        80.6208\n",
      "7        80.6208\n",
      "8        80.6208\n",
      "9        80.6208\n",
      "10       80.6208\n",
      "11       80.6208\n",
      "12       80.6208\n",
      "13       80.7396\n",
      "14       80.6208\n",
      "15       80.7396\n",
      "16       80.6208\n",
      "17       76.4292\n",
      "18       80.7396\n",
      "19       80.6208\n",
      "20       80.6208\n",
      "21       80.6208\n",
      "22       76.4153\n",
      "23       80.6208\n",
      "24       80.6208\n",
      "25       80.6833\n",
      "26       80.7188\n",
      "27       80.6208\n",
      "28       80.6208\n",
      "29       80.6208\n",
      "30       80.6208\n",
      "31       80.6208\n",
      "32       76.4153\n",
      "33       80.6208\n",
      "34       80.6208\n",
      "35       80.6416\n",
      "36       80.6139\n",
      "37       80.7396\n",
      "38       80.6208\n",
      "39       80.6208\n",
      "40       80.6208\n",
      "41       80.6208\n",
      "42       80.6208\n",
      "43       80.7188\n",
      "44       80.6208\n",
      "45       76.4292\n",
      "46       80.6208\n",
      "47       80.6208\n",
      "48       80.6208\n",
      "49       80.6208\n",
      "50       80.6208\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import calinski_harabasz_score\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "train = pd.read_csv('Train_Data.csv',index_col = 0)\n",
    "test = pd.read_csv('Test_Data.csv',index_col = 0)\n",
    "whole = pd.concat([train,test],axis=0)\n",
    "whole.reset_index(drop=True,inplace=True)\n",
    "features = whole.drop(columns=['Family','Genus','Species'])\n",
    "label_class = whole.iloc[:,[22,23,24]]\n",
    "                   \n",
    "                   \n",
    "\n",
    "hamming_loss_vector = pd.DataFrame(index=np.arange(1,51),columns=['Hamming Loss'])\n",
    "hamming_distance_vector = pd.DataFrame(index=np.arange(1,51),columns=['Hamming Distance'])\n",
    "hamming_score_vector = pd.DataFrame(index=np.arange(1,51),columns=['Hamming Score'])\n",
    "                   \n",
    "for mc in np.arange(0,50):\n",
    "    \n",
    "    print(mc)  # to keep iteration track\n",
    "                   \n",
    "    sil = pd.DataFrame(index=np.arange(2,51),columns=['Silhouette_Score_Average'])\n",
    "    for i in np.arange(2,51):\n",
    "        kmeans = KMeans(n_clusters=i).fit(features)\n",
    "        pred_clusters = kmeans.labels_\n",
    "        sil.iloc[i-2] = silhouette_score(features,pred_clusters)\n",
    "\n",
    "    max_sil = sil.max(axis=0)\n",
    "    max_indx = np.argmax(sil['Silhouette_Score_Average'].to_numpy().flatten())\n",
    "    k_selected = max_indx + 2\n",
    "\n",
    "    kmeans = KMeans(n_clusters = k_selected).fit(features)\n",
    "    cluster_groups = kmeans.labels_\n",
    "\n",
    "    cluster_triplet_df = pd.DataFrame(index = np.arange(0,k_selected),columns=['Fam_Clus','Gen_Clus','Spec_Clus']) # has cluster label details\n",
    "    for q in np.arange(0,k_selected):\n",
    "        for l in np.arange(0,3):\n",
    "            loc_build = []\n",
    "            for p in np.arange(0,features.shape[0]):\n",
    "                if cluster_groups[p] == q:\n",
    "                    loc_build.append(label_class.iloc[p,l])\n",
    "\n",
    "            build = np.array(loc_build)\n",
    "            build_counts = np.bincount(build)\n",
    "            highest_freq = np.argmax(build_counts)\n",
    "            cluster_triplet_df.iloc[q,l] = highest_freq\n",
    "\n",
    "\n",
    "    cluster_predictions_label_class = pd.DataFrame(index = np.arange(0,features.shape[0]),columns = ['Family','Genus','Species'])\n",
    "\n",
    "    for i in np.arange(0,features.shape[0]):\n",
    "        cluster_predictions_label_class.iloc[i,0] = cluster_triplet_df.iloc[cluster_groups[i],0]\n",
    "        cluster_predictions_label_class.iloc[i,1] = cluster_triplet_df.iloc[cluster_groups[i],1]\n",
    "        cluster_predictions_label_class.iloc[i,2] = cluster_triplet_df.iloc[cluster_groups[i],2]\n",
    "\n",
    "\n",
    "    mis = 0\n",
    "    for i in np.arange(0,features.shape[0]):\n",
    "        for j in np.arange(0,3):\n",
    "            if cluster_predictions_label_class.iloc[i,j] != label_class.iloc[i,j]:\n",
    "                mis = mis + 1\n",
    "\n",
    "\n",
    "    hamming_loss = (mis/(3*features.shape[0]))*100\n",
    "    \n",
    "    hamming_loss_vector.iloc[mc,0] = hamming_loss               \n",
    "\n",
    "    hamming_distance = mis/features.shape[0]\n",
    "    \n",
    "    hamming_distance_vector.iloc[mc,0] = hamming_distance\n",
    "\n",
    "\n",
    "    hs = 0\n",
    "    for i in np.arange(0,features.shape[0]):\n",
    "\n",
    "        sam_loc = 0\n",
    "        for j in np.arange(0,3):\n",
    "\n",
    "            if cluster_predictions_label_class.iloc[i,j] == label_class.iloc[i,j]:  # note the equality here, true calculated\n",
    "                sam_loc = sam_loc + 1\n",
    "\n",
    "        pred_loc = cluster_predictions_label_class.iloc[i,:].to_numpy().flatten()\n",
    "        true_loc = label_class.iloc[i,:].to_numpy().flatten()\n",
    "\n",
    "        uni_rep_strng = np.concatenate((pred_loc,true_loc)).flatten()  # union, absolute, with repetitions\n",
    "\n",
    "        uni_bin = np.bincount(uni_rep_strng.astype(int))\n",
    "\n",
    "        for m in np.arange(0,uni_bin.size):\n",
    "            if uni_bin[m] > 1:\n",
    "                uni_bin[m] = 1\n",
    "\n",
    "        dist_cnt = np.sum(uni_bin)    # count of total distinct elements\n",
    "\n",
    "        hs_loc = sam_loc/dist_cnt\n",
    "\n",
    "        hs = hs + hs_loc          # running sum of HS\n",
    "\n",
    "\n",
    "    hamming_score = (hs/features.shape[0])*100\n",
    "    \n",
    "    hamming_score_vector.iloc[mc,0] = hamming_score\n",
    "                   \n",
    "            \n",
    "\n",
    "print('The hamming loss vector for all iterations, in %, is : \\n',hamming_loss_vector)\n",
    "\n",
    "print('The hamming distance vector for all iterations is : \\n',hamming_distance_vector)\n",
    "                   \n",
    "print('The hamming score/accuracy score vector for all iterations, in %, is : \\n',hamming_score_vector)                   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As can be seen, the values change very little through all 50 Monte-Carlo iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average hamming loss over 50 iterations is in % : \n",
      " Hamming Loss    22.41464\n",
      "dtype: float64\n",
      "The average hamming distance over 50 iterations is : \n",
      " Hamming Distance    0.672439\n",
      "dtype: float64\n",
      "The average hamming score/accuracy over 50 iterations is in %: \n",
      " Hamming Score    80.299736\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "avg_hamming_loss = hamming_loss_vector.mean(axis=0)\n",
    "avg_hamming_distance = hamming_distance_vector.mean(axis=0)\n",
    "avg_hamming_score = hamming_score_vector.mean(axis=0)\n",
    "\n",
    "print('The average hamming loss over 50 iterations is in % : \\n',avg_hamming_loss)\n",
    "print('The average hamming distance over 50 iterations is : \\n',avg_hamming_distance)\n",
    "print('The average hamming score/accuracy over 50 iterations is in %: \\n',avg_hamming_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
