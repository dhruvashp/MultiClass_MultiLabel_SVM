{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HW5\n",
    "b\n",
    "Summary Notes\n",
    "\n",
    "Data : Raw, SVM : RBF/Gaussian Kernel\n",
    "Estimated Test Error : 0.82 %\n",
    "Test Error : 0.679 %\n",
    "Run Time : Normal \n",
    "C = 100\n",
    "Gamma = 3\n",
    "\n",
    "Data : Standardized, SVM : RBF/Gaussian Kernel\n",
    "Estimated Test Error : 1.36 % \n",
    "Test Error : 0.756 %\n",
    "Run Time : Very Large\n",
    "C = 10\n",
    "Gamma = 0.1\n",
    "\n",
    "\n",
    "Data : Standardized, SVM : Linear with L1 Penalty\n",
    "Estimated Test Error : 5.5 %\n",
    "Test Error : 4.72 %\n",
    "Run Time : Small\n",
    "C = 100\n",
    "\n",
    "\n",
    "Data : Standardized, SVM : Linear with L1 Penalty, SMOTE Fit\n",
    "Estimated Test Error : 7.34 %\n",
    "Test Error : 6.91 %\n",
    "Run Time : Large\n",
    "C = 10\n",
    "\n",
    "\n",
    "As can be seen in the summary, the test error (estimated and actual) is the smallest for Raw Data (Normalized here) with RBF Kernel. Also the run time for it is nominal.\n",
    "\n",
    "Standardizing this dataset and then using a Gaussian Kernel for me took an extremely long time to run. The C and gamma range for both the problems had the same length, and the only difference was that the data was standardized. Thus for some reason, for the Gaussian Kernel, after standardizing the dataset, the fit took a longer time to converge. As such this didn't even improve performance as can be seen from the test errors. The test errors, while still nominal, are still a little higher than that for the raw data set used with Gaussian Kernel.\n",
    "\n",
    "SMOTE'ing the dataset, for Linear SVM with L1 Penalty, increased the run times and actually didn't improve the accuracy. The errors actually increased for the SMOTE fit.\n",
    "\n",
    "Thus, if one wants to resolve class imbalance (which does exist here for some classes in each label), one could select another approach other than SMOTE. Again note that only test errors are not enough, we need to also measure ROC, AUC and see how much the imbalance affects the classification. In that sense SMOTE'd data maybe a better performer, 'making even' the misclassification errors for each class, in each label.\n",
    "\n",
    "Thus if one goes by the summary table,\n",
    "\n",
    "For Gaussian Kernel, there is no need to standardize the data (one can pick the raw/normalized data and work with it)\n",
    "\n",
    "And SMOTE may be used over just the normal Linear SVM with L1 penalty, if it does address class imbalance\n",
    "\n",
    "\n",
    "FINAL CONCLUSION :\n",
    "\n",
    "FOR GAUSSIAN KERNEL : No need to standardize, use raw data, especially if it is Normalized, which here it is. Standardization for some reason drastically increases run time and convergence.\n",
    "\n",
    "FOR LINEAR SVM WITH L1 PENALTY : Looking at test errors, the un-SMOTE'd data actually performs better and has lower run time. We should pick SMOTE if it does deal with class imbalance, by obtaining misclassification for each class in each label, and how crucial dealing with class imbalance is, for the current dataset. If SMOTE doesn't affect imbalance, doesn't remedy it, one should select the un-SMOTE'd dataset, or use another technique that deals with class imbalance, other than SMOTE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
